{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# MNIST Classification\n",
    "In this exercise we will explore the performance of several classification techniques on classifying handwritten digits. The canonical dataset used is the MNIST dataset (https://en.wikipedia.org/wiki/MNIST_database). We will evaluate classifier performance through train/validation/test sets provided to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This exercise will use TensorFlow (https://en.wikipedia.org/wiki/TensorFlow). <b>Ignore all warnings produced by the tensorflow library (or others that you are required to use in this project, e.g. scikit-learn).</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from utils import get_data_extract\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the following line to retrieve the data and generate the training, validation, and test sets using the function <b>get_data_extract()</b> provided in <b>utils.py</b>. <br>\n",
    "<b>We want you to use the training, validation and test sets provided by this function, exclusively.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = get_data_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 0. Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The resolution of the images are all $28\\times 28$. The corresponding feature vector of an image is a $28^2=784$ length 1D array representing the row-major flattened version of the image (i.e. the rows are concatenated top-down). All values in the array are in the range $[0,1]$ representing the grayscale value at that point. Note to get the pixel value, you would have to multiply these values by $255$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "a) What are the dimensions of $X_{train}, X_{val}, X_{test}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dimensions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "b) Display the first two images of $X_{train}$. (You may find the <b>np.reshape()</b> and <b>plt.imshow()</b> methods useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first two training images here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "c) Print out the first two labels in $Y_{train}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first two training labels here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now use the MNIST data extracts above to compare various classification algorithms. <b>ONLY use the data extracts provided above. </b> We are primarily interested in two metrics: \n",
    "1. the test set accuracy (0.0 being all incorrect and 1.0 being all correct)\n",
    "2. time it takes to train the model and produce classifications for the <b>test set</b> <br>\n",
    "\n",
    "$X_{train}, Y_{train}$ will be used for training while $X_{test}, Y_{test}$ will be used for evaluating performance. Some models will use $X_{val}, Y_{val}$ for parameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 1. LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "a) Use scikit-learn's LDA algorithm <b>LinearDiscriminantAnalysis()</b> to train an LDA-model. Only use the $X_{train}, Y_{train}$ data to fit the model. You should also note the time (in seconds) it takes to train the model and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA and report time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "b) Use the <b>score()</b> function provided by LinearDiscriminantAnalysis() on the trained model to produce the accuracy on the test set $X_{test}, Y_{test}$ Also print the time it takes to produce these predictions. Clearly format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LDA on X_test, Y_test and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 2. QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Repeat the exercise above for sklearn's QDA algorithm <b>QuadraticDiscriminantAnalysis()</b>. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train QDA and report time\n",
    "# Test QDA and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Repeat the exercise above for sklearn's <b>LogisticsRegression()</b> algorithm. You might find the following arguments helpful when initializing the model: <b>penalty='l1', C=1.0, tol=0.01</b>. These parameters will help speed up the algorithm significantly. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression and report time\n",
    "# Test Logistic Regression and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<b>****** The folowing models take a long time to run so we suggest reading all parts of the exercise first before implementing code. *****</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 4. k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "a) Repeat the classification exercises above for sklearn's kNN algorithm <b>KNeighborsClassifier()</b> using <b>k=1</b>. You might find the following arguments helpful when initializing the model: <b>algorithm='kd_tree', metric='minkowski', p=2</b>. These parameters will help speed up the algorithm significantly. However, the predictions will still be very slow. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train kNN for k=1 and report time\n",
    "# Test kNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "b) For the kNN model trained above, what is the prediction accuracy on the <b>training set</b> $X_{train}, Y_{train}$ (this will take a while to compute)? Compare this to the the prediction accuracy on the training set for the <b>LogisticRegression model</b>? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report kNN training accuracy\n",
    "# Report Logistic Regression training accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "c) Does anything surprise you about the Training set accuracies above? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "d) Can you think why there is such a large difference between the kNN algorithms's training and prediction times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "e) For now, we have only tried <b>k=1</b> (choose the closet neighbor) according to the Euclidean distance metric <b>p=2</b>. Repeat the exercise above for the following combinations of parameters: <b> k $\\in$ {1, 3}, p $\\in$ {2, 3} </b>. Note that p=2 is the 2-norm (Euclidean distance) and p=3 is the 3-norm. Train each of the models on the training set and evaluate the accuracy on the <b>validation set</b> $X_{val}, Y_{val}$. <b>NOTE: this might take a while!</b> Report the validation set accuracy for each model. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train kNN for all combinations of parameters above and report validation accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "f) Based on the scores on the validation set, which parameters give the best model? Report the time taken to train the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "g) Using the best model, evaluate performance on the <b>test set</b>. Produce the prediction accuracy score and time taken to produce predictions. Please format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test best kNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 5. Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As you have noticed by now, kNN is pretty slow. However, you might also have noticed, it achieves\n",
    "better accuracy than the other classification algorithms we have experimented on.\n",
    "Our next goal is to come up with strategies to speed up the nearest neighbor search by trying some \n",
    "approximate nearest neighbor algorithms. Our hope is to sacrfice the accuracy as little as possible while gaining on compuational efficiency.\n",
    "\n",
    "One approximate nearest neighbor algorithm is known as <b>Locality Sensitive Hashing (LSH)</b>. \n",
    "You can find an overview on Wikipedia: https://en.wikipedia.org/wiki/Locality-sensitive_hashing\n",
    "For the more curious, this paper discusses a practical algorithm called <b>LSH Forest</b>: http://infolab.stanford.edu/~bawa/Pub/similarity.pdf\n",
    "You will be using sklearn's LSH Forest implementation <b>LSHForest()</b> (note: it is not the most efficient implementation but will work for our purposes).\n",
    "\n",
    "You will now repeat the kNN exercise using LSH Forests, specifically:\n",
    "1. Use sklearn's LSH Forest to train the model on the training data\n",
    "2. Using the model, produce k-approximate nearest neighbors for each new data point.\n",
    "3. Using the k-approximate neighbors, produce a final prediction using the majority rule: \n",
    "<b>the prediction is the label that was produced by most of the approximate neighbors</b>. (You may find Python's <b>Counter()</b> data structure useful here along with its <b>most_common()</b> method).\n",
    "4. Using the framework described above, iterate through the combinations of the following parameters and report the model with the best accuracy on the validation set:  \n",
    "<b>n_estimators$\\in$[20, 40, 80],\n",
    "n_candidates$\\in$[10, 20],\n",
    "n_neighbors$\\in$[1, 3, 5]</b> (You may find the library's method <b>accuracy_score()</b> useful here). \n",
    "5. Finally, using the best model, produce the following:\n",
    "Time taken to train the model; Time taken to produce Test set predictions; Test set accuracy\n",
    "\n",
    "We suggest writing two helper functions to streamline the implementation:\n",
    "- <b>lsh_predictions()</b>: produces predictions for a given set of k-approximate neighbors\n",
    "- <b> runLSH()</b>: performs training and validation for a given set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate LSH for all combination of parameters above\n",
    "# Report parameters for the best model\n",
    "# Report training time, test set accuracy and time for best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What are the tradeoffs exposed by the LSH algorithm for the MNIST dataset classification problem? Would you prefer an approximate algorithm like LSH Forest over the k-NN algorithm used earlier?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 6. Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now complete the tasks above using a simple Neural Network model.\n",
    "This portal comes with a tensorflow installation (see the imports at the very top of this file).\n",
    "Your task is the following:\n",
    "1. Adapt the tensorflow tutorial here (https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners) to train a simple Neural Network model\n",
    "2. You are required to use <b>ONLY</b> the $X_{train}, Y_{train}, X_{val}, Y_{val}, X_{test}, Y_{test}$ subsets provided earlier in this assignment. <b>DO NOT use any other subsets of the mnist dataset: you will have to adapt the tutorial to use the data provided in this assignment.</b>\n",
    "3. You will need to write a custom one-hot encoder for the labels\n",
    "   Hint: you might find the following libraries useful:\n",
    "\t\tfrom sklearn.preprocessing import LabelEncoder\n",
    "\t\tfrom sklearn.preprocessing import OneHotEncoder\n",
    "4. Note that you will not need to use any validation in this part. Train using $X_{train}, Y_{train}$.\n",
    "5. Finally, produce the following: Time taken to train the model; Time taken to produce Test set predictions; Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement simpleNN\n",
    "# Train simpleNN and report time\n",
    "# Test simpleNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 7. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now complete the tasks above using a more complicated model: Convolutional Neural Network.\n",
    "\n",
    "Your task is the following:\n",
    "1. Adapt the CNN tensorflow tutorial here (https://www.tensorflow.org/versions/r1.1/get_started/mnist/pros) to train a Convolutional Neural Network model\n",
    "2. You are required to use <b>ONLY</b> the $X_{train}, Y_{train}, X_{val}, Y_{val}, X_{test}, Y_{test}$ subsets provided earlier in this assignment. <b>DO NOT use any other subsets of the mnist dataset: you will have to adapt the tutorial to use the data provided in this assignment.</b>\n",
    "3. Use the same one-hot encoder as the previous part\n",
    "4. Note that you will not need to use any validation in this part. Train using $X_{train}, Y_{train}$.\n",
    "5. <b>Important</b>: use a maximum of 1500 iterations with a batch size of 100.\n",
    "6. Finally, produce the following:\n",
    "\tTime taken to train the model; Time taken to produce Test set predictions; Test set accuracy\n",
    "\n",
    "<b>Important Note:</b> If you are experiencing kernel issues during testing, we suggest finding the accuracies on the test set in chunks of 1000 then averaging. Since there are 3000 data points in the test set, you would take the average of the accuracies on the first 1000, second 1000, and last 1000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement CNN\n",
    "# Train CNN and report time\n",
    "# Test CNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Comment on the features of the various algorithms you have used in this assignment and the tradeoffs between computational efficiency and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
